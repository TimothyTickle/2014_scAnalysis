```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE)
```

scAnalysis
========================================================
author: Timothy Tickle and Brian Haas
css: 2014_scAnalysis.css
date: September 23, 2014

Logistics
===
class:small-code

```{r, tidy=TRUE}
library(boot) #SCDE
library(caret) #Near-zero filter
library(GMD) #Cluster selection on dendrograms
library(gplots) #Colorpanel
library(mclust) #Selection of clusters
library(scatterplot3d) #3D plotting
library(scde) #Statistical inference (bayesian mixed model)
library(vegan) #PCoA, distance metrics
source("heatmap.3b.R") #Custom HCL
source("cell_cycle_plot.R") #Custom plot for cell cycle
source("Modules.R") #
```

Today's Data Set
===

- Describe data set

How do we get it?
===
class:small-code

```{r}
# Load tab delimited file
data = read.delim( file.path("data","GSE29087_L139_expression_tab.txt"), row.names = 1 )

# For convenience splitting the data frame in to metadata and data
metadata = data[ 1:6 ]
data = data[ -1 * 1:6 ]

# Remove features without counts
zero.features <- which( apply( data, 1, sum ) == 0 )
length( zero.features )
data = data[ -1 * zero.features, ]
metadata = metadata[ -1 * zero.features, ]

# Get groupings
data.groups=c("ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF","ES","ES","ES","ES","MEF","MEF","MEF","MEF")
data.groups = c( rep("ES",48),rep("MEF",48))
# Get colors to plot with
data.groups.colors <- func_factor_to_metadata_color( as.factor( data.groups) )$vctr_grouping_colors
```
TODO update

Always look at your data
===

# Add picture

A quick look at the data
===
class:small-code

```{r}
dim( data )
names( data )
summary(data)

dim( metadata )
names( metadata )
summary(metadata)
```

Let's characterize this data.
===

- Is the data normal?
- Sparsity / zero-inflation
- Overdispersed

Normality?
===
class:small-code

```{r}
feature.sum = apply( data, 1, sum )
feature.sum.sorted = sort( feature.sum )
plot( log( feature.sum.sorted ), main = "Total gene counts throughout samples", ylab = "Log total counts", xlab = "Index after sorting" )
abline( v = c(1, 3729,7457,11180,14913), col = c("red", "violet","cyan","blue","green"))
# Min 1, 1st quartile 3729, Median 7457, 3rd quartile 11180, Max 14913
```

Normality?
===
class:small-code

```{r}
feature.sum.order <- order( feature.sum )
index_min <- feature.sum.order[ 1:10 ]
index_q1 <- feature.sum.order[ 3724:3723 ]
index_median <- feature.sum.order[ 7452:7461 ]
index_q3 <- feature.sum.order[ 11175:11184 ]
index_max <- feature.sum.order[ 14908:14913 ]
plot( density( as.matrix( data[ index_min[1], ] ) ), col = "red" )
```

Zooming in to Gene Distributions
===
class:small-code

```{r, echo = FALSE, fig.keep='last'}
plot( x=0,y=0,type="p", xlim=c(0,100), ylim=c(0,.2) )
for( i_min_plot in index_min ){ lines( density( as.matrix( data[ i_min_plot, ])), col = "red", add = TRUE)}
for( i_q1_plot in index_q1 ){ lines( density( as.matrix( data[ i_q1_plot, ])), col = "violet", add = TRUE)}
for( i_median_plot in index_median ){ lines( density( as.matrix( data[ i_median_plot, ])), col = "cyan", add = TRUE)}
for( i_q3_plot in index_q3 ){ lines( density( as.matrix( data[ i_q3_plot, ])), col = "blue", add = TRUE)}
for( i_max_plot in index_max ){ lines( density( as.matrix( data[ i_max_plot, ])), col = "green", add = TRUE)}
```

Sparsity
===
class:small-code

```{r}
# Check samples for read depth
sample.depth <- apply( data, 2, sum )
summary(sample.depth )
```
---
```{r}
barplot( sort( sample.depth ), main = "Sample Depth ", xlab = "Sample", ylab = "Depth")
```

Sparsity
===
class:small-code

```{r}
# Percent zero by feature expression
feature.percent.zero <- apply( data, 1, function(x){ length( which(x==0))/length(x)})
feature.mean.no.zero <- apply( data, 1, function(x){ mean( x[ which(x!=0) ] ) })
plot( feature.percent.zero, log( feature.mean.no.zero ), xlab = "log mean", ylab = "Percent Zero", main = "Feature Sparsity by Expression" )
```

Overdispersion
===
class:small-code

```{r}
# SD vs Mean
feature.sd.with.zero <- apply( data, 1, sd )
feature.mean.with.zero <- apply( data, 1, mean )
feature.sd.no.zero <- apply( data, 1, function(x){ sd( x[ which(x !=0 )])})
plot( log( feature.mean.no.zero ), log( feature.sd.no.zero ), xlab = "Mean (Log)", ylab = "SD (Log)", main = "SD vs mean (ignoring zeros)" )
plot( log( feature.mean.with.zero ), log( feature.sd.with.zero ), xlab = "Mean (Log)", ylab = "SD (Log)", main = "SD vs mean (ignoring zeros)" )
```

Can QC Help?
===

- Removing very sparse features
- Imputing outliers

Removing Sparse Features
===
class:small-code

```{r}
sample.percentile = apply( data, 2, function(x){ quantile(x[x !=0 ], .5)})
feature.noise = which(apply( data, 1, min_occurence_at_min_value, sample.percentile ) <= 10)
feature.noise.by.expression = order( apply( data[ feature.noise, ], 1, sum ), decreasing = TRUE)
# What am I removing
plot(density( as.matrix(data[ feature.noise[ feature.noise.by.expression[ 1 ]], ])))
# TODO make a multiple density plot
```

Removing Sparse Features
===
class:small-code

```{r}
dim( data )
dim( metadata )
data = data[ -1 * feature.noise, ]

metadata = metadata[ -1 * feature.noise, ]
dim( data )
dim( metadata )
```

Sample Read Depth: revisited
===
class:small-code

```{r}
sample.depth <- apply( data, 2, sum )
depth.colors = polychromatic_palette( length( sample.depth ) )
sample.depth
```
---
```{r}
barplot( sort(apply( data, 2, sum )))
```

Can Transforms / Normalization Help?
===

TODO NEED CODE

Challenge
===

- We have a large range of read depth per sample
  - Is this a problem?

Waste Not, Want Not
===

- Rarefy?

Dimensionality Reduction and Ordination
===

- A frequently used method is PCA

PCA: in quick theory
===

- Describe PCA

PCA: in practice
===

- Things to be aware of

PCA: in code
===
class:small-code

```{r, echo=TRUE}
# Row center and log
data.scaled = t( scale( t( as.matrix( log( data + 1 ) ) ), center=TRUE, scale=TRUE ) )
# Remove constant rows
# TODO data.scaled = data.scaled[, -1 * nearZeroVar( data.scaled ) ]
# Perfrom PCA
results.pca = prcomp( data.scaled, retx = TRUE )
```

PCA: in code
===
class:small-code

```{r, echo=TRUE}
plot( results.pca$rotation[,1], results.pca$rotation[,2], pch=16 )
```

PCA: by depth
===
class:small-code

```{r,echo=FALSE}
min.pc1 = min( results.pca$rotation[,1] )
min.index = which(sort(results.pca$rotation[,1]) == min.pc1 )[1]
min.pc1 = round(min.pc1,4)
median.pc1 = median(c(0,results.pca$rotation[,1]))
median.index = which(sort(results.pca$rotation[,1]) == median.pc1 )[1]
median.pc1 = round(median.pc1,4)
max.pc1 = max( results.pca$rotation[,1] )
max.index = which(sort(results.pca$rotation[,1]) == max.pc1 )[1]
max.pc1 = round(max.pc1,4)
```
```{r, echo=TRUE}
plot( results.pca$rotation[,1], results.pca$rotation[,2], pch=16, col= depth.colors, xlab="PC1", ylab="PC2", main="PCA by Sample Depth" )
legend( "topright", c(paste(max.pc1," (Max)"), paste(median.pc1," (Median)"), paste(min.pc1," (Min)")), fill=c(depth.colors[max.index], depth.colors[median.index], depth.colors[min.index]) )
```

PCA: 3D with caution
===
class:small-code

```{r}
scatterplot3d( x=results.pca$rotation[,1], y=results.pca$rotation[,3], z=results.pca$rotation[,2], color = depth.colors, xlab="PC1", ylab="PC3", zlab="PC2", main="3D PCA using Components 1-3" )
```

Alternatives?
===

- Principle Coordinates Analysis
- Weighted PCA
  - Different than Sparse PCA

PCoA: in quick theory
===

PCoA: in practice
===

#? Add picture
- The magic is in the metric
- By default you only get 2 dimensions

PCoA: in code (Bray-curtis)
===
class:small-code

```{r, echo=FALSE}
pcoa.data = data
pcoa.data = sweep( pcoa.data, 2, colSums( pcoa.data ), "/")
nmds.b.c.result = metaMDS( comm=t(pcoa.data), distance="bray", k=2, autotransfer=FALSE, trymax=10)
```
```{r}
plot( nmds.b.c.result$points[,1], nmds.b.c.result$points[,2], col=depth.colors, main="Ordination by Bray Curtis")
legend( "topleft", c(paste(max.pc1," (Max)"), paste(median.pc1," (Median)"), paste(min.pc1," (Min)")), fill=c(depth.colors[max.index], depth.colors[median.index], depth.colors[min.index]) )
```

PCoA: in code (Jaccard)
===
class:small-code

```{r, echo=TRUE}
nmds.j.result = metaMDS( comm=t(pcoa.data), distance="jaccard", k=2, autotransfer=FALSE, trymax=10)
plot( nmds.j.result$points[,1], nmds.j.result$points[,2], col=depth.colors, main="Ordination by Jaccard")
legend( "topleft", c(paste(max.pc1," (Max)"), paste(median.pc1," (Median)"), paste(min.pc1," (Min)")), fill=c(depth.colors[max.index], depth.colors[median.index], depth.colors[min.index]) )
```

Next Steps in Ordination
===

Other options to explore
- Wieghted PCA

Unsupervised Substructure Discovery
===

Often a goal of scProjects is to describe new structure to a group of cells:
- Heterogeniety of tumor populations
- Novel steps in development
- Robust / dynamic cellular signalling

PCA + ANOVA: PCA
===
class:small-code

```{r}
results.pca.features <- prcomp( scale( log( t(data) + 1 ), center=TRUE, scale=TRUE), retx=TRUE)
plot( results.pca.features)
```

PCA + ANOVA: PCA
===
class:small-code

```{r}
hist( abs( results.pca.features$rotation[,1] ), main="Feature Loadings (Abs)", xlab="Feature loadings (Abs)" )
ordered.pca.loadings <- order( results.pca.features$rotation[,1],decreasing = TRUE )
extreme.ends.pca <- c(ordered.pca.loadings[1:250], ordered.pca.loadings[5154:5654])
abline( v=results.pca.features$rotation[,1][extreme.ends.pca], col="#ff000010")
```

PCA + ANOVA: visualize
===
class:small-code

```{r}
data.scaled.subset = t( scale( t( as.matrix( log( data[ extreme.ends.pca, ] + 1 ) ) ), center=TRUE, scale=TRUE ) )
heatmap( data.scaled.subset )
```

PCA + Anova: select sample groups
===
class:small-code

```{r}
gmd.dist <- dist( t( data.scaled.subset ) )
hclust.aov <- hclust( gmd.dist )
gmd.clust <- css.hclust( gmd.dist, hclust.aov )
gmd.elbow.groups <- elbow.batch( gmd.clust, ev.thres=0.3, inc.thres=0.1 )
tree.groups <- as.factor( cutree( hclust.aov, k=gmd.elbow.groups$k ) )
```

PCA + ANOVA: select sample groups
===
class:small-code

```{r}
heatmap( data.scaled.subset, vctr_grouping=tree.groups ) 
```

PCA + ANOVA: Another view
===
class:small-code

```{r}
results.pca.subset = prcomp( data.scaled.subset, retx = TRUE )
plot( results.pca.subset$rotation[,1], results.pca.subset$rotation[,2], pch=16, xlab="PC1", ylab="PC2", main="PCA by Sample Depth", col = depth.colors )
```

PCA + ANOVA: Another view
===
class:small-code

```{r}
tree.group.colors = func_factor_to_metadata_color( tree.groups )$vctr_grouping_colors
plot( results.pca$rotation[,1], results.pca$rotation[,2], pch=16, xlab="PC1", ylab="PC2", main="PCA by Grouping (GMD)", col = tree.group.colors )
```

PCA + ANOVA: select genes
===
class:small-code

```{r}
do_aov <- function(x, tree.groups){
ret_aov = aov( x ~ tree.groups )
return( summary(ret_aov)[[1]][["Pr(>F)"]][1] ) }
pca.list.p = apply( data.scaled.subset, 1, do_aov, tree.groups=tree.groups )
pca.list.q = p.adjust( pca.list.p )
pca.list.names = names( pca.list.q[ pca.list.q <= 0.05 ] )
```

mclust
===
class:small-code

```{r, echo=FALSE}
plot( results.pca$rotation[,1], results.pca$rotation[,2], pch=16 )
mclust.results = Mclust(results.pca$rotation[,c(1:2)])
mclust.groups = mclust.results$classification
plot( mclust.results )
```

PCA + ANOVA: Select Gene Groups
===
class:small-code

```{r}
data.scaled.subset = data.scaled.subset[ pca.list.names, ]
heatmap( data.scaled.subset )
gmd.dist.genes <- dist( data.scaled.subset )
hclust.aov.genes <- hclust( gmd.dist.genes )
gmd.clust.genes <- css.hclust( gmd.dist.genes, hclust.aov.genes )
gmd.elbow.genes <- elbow.batch( gmd.clust.genes, ev.thres=0.4, inc.thres=0.1 )
tree.genes <- as.factor( cutree( hclust.aov.genes, k=gmd.elbow.genes$k ) )
```

Supervised Analysis: Known gene groups
===
class:small-code

NEED CODE
# Read in data
gbm_data <- read.delim("data/GBM_data_matrix.txt", row.names=1)
# Reduce to genes of interest
gbm_group_ <- read.delim("data/.txt")
gbm_group_ <- read.delim("data/.txt")
gbm_group_ <- read.delim("data/.txt")
gbm_group_ <- read.delim("data/.txt")

# Reduce to genes of interest
gbm_group_all <- unique( gbm_group_, gbm_group_, gbm_group_, gbm_group_)
gbm_data <- gbm_data[ gbm_group_all, ]
# Visualize before
heatmap( as.matrix( gbm_matrix) )

# Make average

# View after
heatmap( gbm_averaged )

scOpportunities: cell cycle plot
===

# Add in picture

Statistical Inference in scData
===

- Bayesian analysis
- Mixture Models
- Bimodal assumptions

SCDE: in quick theory
===

SCDE: in practice
===

SCDE: in code
===
class:small-code

```{r}
names( data.groups ) = data.groups
data.groups <- as.factor( data.groups )
o.ifm <- scde.error.models( as.matrix( data ), groups = data.groups, n.cores=1, threshold.segmentation=TRUE, save.crossfit.plot=FALSE, save.model.plots=FALSE, verbose=1 )
# Filter out cell (QC)
o.ifm <- o.ifm[ o.ifm$corr.a > 0, ]
```

SCDE: in code
===
class:small-code

```{r}
o.prior <- scde.expression.prior(models=o.ifm,counts=as.matrix(data),length.out=400,show.plot=FALSE)
# Perform T-test like analysis
ediff <- scde.expression.difference(o.ifm,as.matrix(data),o.prior,groups=as.factor(data.groups),n.randomizations=100,n.cores=1,verbose=1)
write.table(ediff[order(abs(ediff$Z),decreasing=T),],file="scde_results.txt",row.names=T,col.names=T,sep="\t",quote=F)
```

PCoA: in code (Reciprocal)
===
class:small-code

```{r}
names(data.groups) = data.groups
dist.recip <- reciprocal_weighting( x=as.matrix(data), groups=data.groups )
nmds.r.result = metaMDS( comm=dist.recip, k=2, autotransfer=FALSE )
plot( nmds.r.result$points[,1], nmds.r.result$points[,2], col=data.group.colors, main="Ordination by Reciprocal Weighting")
```

PCoA: in code (Reciprocal)
===
class:small-code

Attempting with 7 dimensions
```{r}
names(data.groups) = data.groups
nmds.r.result = metaMDS( comm=dist.recip, k=7, autotransfer=FALSE )
plot( nmds.r.result$points[,1], nmds.r.result$points[,2], col=data.group.colors, main="Ordination by Reciprocal Weighting")
```

What did we find ?
===

- Unsupervised discovery of substructure
- Inference on known structure
- How do we connect this to biology?

Gene Set Enrichment Analysis: GSEA
===

- Not specifically related to scAnalysis
- Does help round out the story
- Covered in other section
- Many options
  - DAVID (online or R library RDAVIDWebService)
  - GSEA (online or many libraries)
    - wilcoxGST from the limma library
    - GSEABase
    
GSEA: briefly described
===

What did we find ???
===


Summary: of the data
===

- We are still understanding scData and how to apply it
  - Not normal
  - Zero-inflated
  - Over-dispersed
  - Very noisey
- Keeping these characteristics in analysis assumptions

Summary: of methods
===


Summary: of today
===

- Created expectations on scData
- Applied 3 ordination techniques
- Tried 2 methods to detect substructure
- Applied known structure to a data set
- Applied 1 statistical inference method

Thank you
===

- Aviv Regev
- Alex Shalek
- Manik Kuchroo
- Rahul Satija
- Itay Tirosh

References
===

Please note this is a collection of many peoples ideas.
Included in the download is a references.txt to document sources.

Questions?
===

# Add picture

Notes: to make a pdf
===

- Create a pdf file before you plot ( can plot multiple plots )
- Close the plotting

```{r}
pdf( "data/my_file.pdf", useDingbats = FALSE ) # Start pdf
plot( 1:10, log(1:10 ) ) # plot in to the pdf file
plot( seq(0,.9,.1), sin(0:9) ) # another plot for the pdf file
dev.off() # Close pdf file ( very important )
```
